{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tobiaswilfert/Documents/University/DM/data-mining-assignments/venv/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n",
      "/Users/tobiaswilfert/Documents/University/DM/data-mining-assignments/venv/lib/python3.10/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Load the files\n",
    "existing_customers = pd.read_excel('data/existing-customers.xlsx')\n",
    "potential_customers = pd.read_excel('data/potential-customers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the score metric\n",
    "def ROI(precision, amount):\n",
    "    return amount * (88*precision - 25.5*(1-precision))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premise\n",
    "As this assignment is a classification problem KNN can be used to classify the data. Noticeably though the dimensionality of the data is very important for KNN and while at first it might seem that the dimensionality of the data is to high, it is worth considering that there are a lot of samples (so the ratio of features/samples is not that high) and that some clever feature engineering might be able to reduce the dimensionality of the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def preprocessing_and_feature_selection(\n",
    "    train_ratio = 0.70,\n",
    "    validation_ratio = 0.15,\n",
    "    test_ratio = 0.15,\n",
    "):\n",
    "    # Do the feature selection\n",
    "    data_x = existing_customers[[\"age\", \"education\", \"education-num\", \"marital-status\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]]\n",
    "    data_y = existing_customers[[\"class\"]]\n",
    "\n",
    "    # Deal with the NaN entries\n",
    "    # - By ignoring the variables that contain the Nan entries.\n",
    "\n",
    "    # Do the conversion from categorical to nominal\n",
    "    data_x = pd.get_dummies(data_x)\n",
    "    data_y = pd.get_dummies(data_y, drop_first=True) \n",
    "\n",
    "    # Split the data into test, training and validation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=1 - train_ratio)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = preprocessing_and_feature_selection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 Recall: 0.6232758620689656 ROI: 53068.64353448277\n",
      "k=2 Recall: 0.46551724137931033 ROI: 19736.741379310344\n",
      "k=3 Recall: 0.6293103448275862 ROI: 50427.543103448275\n",
      "k=4 Recall: 0.5327586206896552 ROI: 29373.206896551725\n",
      "k=5 Recall: 0.6362068965517241 ROI: 50306.112931034484\n",
      "k=6 Recall: 0.5698275862068966 ROI: 34826.95818965517\n",
      "k=7 Recall: 0.6405172413793103 ROI: 51399.39181034482\n",
      "k=8 Recall: 0.5741379310344827 ROI: 36134.50086206896\n",
      "k=9 Recall: 0.6267241379310344 ROI: 47595.41681034482\n",
      "k=10 Recall: 0.5801724137931035 ROI: 36274.262500000004\n",
      "k=11 Recall: 0.6310344827586207 ROI: 47644.45344827587\n",
      "k=12 Recall: 0.5801724137931035 ROI: 36112.864224137935\n",
      "k=13 Recall: 0.6198275862068966 ROI: 45029.8327586207\n",
      "k=14 Recall: 0.5844827586206897 ROI: 37694.206034482755\n",
      "k=15 Recall: 0.6206896551724138 ROI: 45802.293103448275\n",
      "k=16 Recall: 0.5836206896551724 ROI: 37318.70862068966\n",
      "k=17 Recall: 0.6094827586206897 ROI: 43763.645689655175\n",
      "k=18 Recall: 0.5732758620689655 ROI: 35807.963362068964\n",
      "k=19 Recall: 0.6025862068965517 ROI: 41906.98318965517\n",
      "k=<bound method BaseEstimator.get_params of KNeighborsClassifier(n_neighbors=1)> Recall: 0.6086235489220564 ROI: 41906.98318965517\n"
     ]
    }
   ],
   "source": [
    "# Do a base line test using the data we have\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "best_clf = None\n",
    "best_roi = 0\n",
    "# Loop over different values of k and see which scores the best\n",
    "for k in range(1, 20):\n",
    "    # Create the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Validate the classifier\n",
    "    y_pred = clf.predict(x_val)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    roi = ROI(precision, y_pred.sum())\n",
    "    print(f\"k={k} Recall: {precision} ROI: {roi}\")\n",
    "\n",
    "    if roi > best_roi:\n",
    "        best_roi = roi\n",
    "        best_clf = clf\n",
    "\n",
    "# Test the classifier\n",
    "y_pred = best_clf.predict(x_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"k={best_clf.get_params} Recall: {precision} ROI: {roi}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount= 3879 ROI=169042.05970149254\n"
     ]
    }
   ],
   "source": [
    "deploy_x = potential_customers[[\"age\", \"education\", \"education-num\", \"marital-status\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\"]]\n",
    "deploy_x = pd.get_dummies(deploy_x)\n",
    "\n",
    "y_pred = best_clf.predict(deploy_x)\n",
    "amount = y_pred.sum()\n",
    "\n",
    "print(f\"Amount= {amount} ROI={ROI(precision, amount)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The obtained ROI is lower than that of the Decision Tree approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking how KNN performs if we just select the features used by the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "def preprocessing_and_aggressive_feature_selection(\n",
    "    train_ratio = 0.70,\n",
    "    validation_ratio = 0.15,\n",
    "    test_ratio = 0.15,\n",
    "):\n",
    "    # Do the feature selection\n",
    "    data_x = existing_customers[[\"education-num\", \"marital-status\", \"capital-gain\"]]\n",
    "    data_y = existing_customers[[\"class\"]]\n",
    "\n",
    "    # Deal with the NaN entries\n",
    "    # - By ignoring the variables that contain the Nan entries.\n",
    "\n",
    "    # Do the conversion from categorical to nominal\n",
    "    data_x = pd.get_dummies(data_x)\n",
    "    data_y = pd.get_dummies(data_y, drop_first=True) \n",
    "\n",
    "    # Split the data into test, training and validation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size=1 - train_ratio)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "    # Convert the data to numpy arrays so that KNN is happy.\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_val = np.ravel(y_val)\n",
    "    y_test = np.ravel(y_test)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = preprocessing_and_aggressive_feature_selection()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 Recall: 0.4534412955465587 ROI: 22745.854251012148\n",
      "k=2 Recall: 0.4064777327935223 ROI: 13619.246963562753\n",
      "k=3 Recall: 0.4785425101214575 ROI: 24809.348987854253\n",
      "k=4 Recall: 0.4744939271255061 ROI: 23081.01943319838\n",
      "k=5 Recall: 0.5740890688259109 ROI: 38746.94979757085\n",
      "k=6 Recall: 0.5676113360323887 ROI: 36860.92064777328\n",
      "k=7 Recall: 0.5676113360323887 ROI: 36860.92064777328\n",
      "k=8 Recall: 0.5522267206477732 ROI: 32939.47125506072\n",
      "k=9 Recall: 0.5854251012145749 ROI: 39840.21376518219\n",
      "k=10 Recall: 0.5522267206477732 ROI: 32939.47125506072\n",
      "k=11 Recall: 0.5530364372469636 ROI: 33095.43643724697\n",
      "k=12 Recall: 0.5506072874493927 ROI: 32739.625506072873\n",
      "k=13 Recall: 0.5506072874493927 ROI: 32739.625506072873\n",
      "k=14 Recall: 0.5506072874493927 ROI: 32739.625506072873\n",
      "k=15 Recall: 0.5538461538461539 ROI: 33475.93846153846\n",
      "k=16 Recall: 0.5538461538461539 ROI: 33475.93846153846\n",
      "k=17 Recall: 0.5554655870445344 ROI: 33940.99109311741\n",
      "k=18 Recall: 0.5522267206477732 ROI: 33125.359919028335\n",
      "k=19 Recall: 0.5522267206477732 ROI: 33162.537651821855\n",
      "k=<bound method BaseEstimator.get_params of KNeighborsClassifier(n_neighbors=9)> Recall: 0.5531547104580813 ROI: 33162.537651821855\n"
     ]
    }
   ],
   "source": [
    "# Find the best k value\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "best_clf = None\n",
    "best_roi = 0\n",
    "# Loop over different values of k and see which scores the best\n",
    "for k in range(1, 20):\n",
    "    # Create the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    # Validate the classifier\n",
    "    y_pred = clf.predict(x_val)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    roi = ROI(precision, y_pred.sum())\n",
    "    print(f\"k={k} Recall: {precision} ROI: {roi}\")\n",
    "\n",
    "    if roi > best_roi:\n",
    "        best_roi = roi\n",
    "        best_clf = clf\n",
    "\n",
    "# Test the classifier\n",
    "y_pred = best_clf.predict(x_test)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"k={best_clf.get_params} Recall: {precision} ROI: {roi}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount= 2956 ROI=110208.72428694903\n"
     ]
    }
   ],
   "source": [
    "deploy_x = potential_customers[[\"education-num\", \"marital-status\", \"capital-gain\"]]\n",
    "deploy_x = pd.get_dummies(deploy_x)\n",
    "\n",
    "y_pred = best_clf.predict(deploy_x)\n",
    "amount = y_pred.sum()\n",
    "\n",
    "print(f\"Amount= {amount} ROI={ROI(precision, amount)}\")\n",
    "# Previous best: Amount= 3879 ROI=169042.05970149254"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "It is not better than the previous approach, interestingly enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
